#+PROPERTY:  header-args :session *R* :tangle ../docs/R/dataSpatial.R :eval no-export
#+OPTIONS: ^:nil

#+begin_src R :exports none :tangle no
setwd('~/github/bookvis/')
#+end_src

#+begin_src R :exports none  
##################################################################
## Initial configuration
##################################################################
## Clone or download the repository and set the working directory
## with setwd to the folder where the repository is located.
#+end_src

* Air Quality in Madrid
\label{sec:airQualityData}

#+begin_src R :exports none
  ##################################################################
  ## Air Quality in Madrid
  ##################################################################
#+end_src

Air pollution is harmful to health and contributes to respiratory and
cardiac diseases, and has a negative impact on natural ecosystems,
agriculture, and the built environment. In Spain, the principal
pollutants are particulate matter (PM), tropospheric ozone, nitrogen
dioxide, and environmental noise[fn:1].

The surveillance system of the Integrated Air Quality system of the
Madrid City Council consists of twenty-four remote stations, equipped
with analyzers for gases ($NO_X$, CO, ozone, $BT_X$, HCs, $SO_2$) and
particles (PM10, PM2.5), which measure pollution in different areas of
the urban environment. In addition, many of the stations also include
sensors to provide meteorological data.

The detailed information of each measuring station can be retrieved
from its own webpage defined by its station code.
#+begin_src R 
  ## codeStations.csv is extracted from the document
  ## http://www.mambiente.munimadrid.es/opencms/export/sites/default/calaire/Anexos/INTPHORA-DIA.pdf,
  ## table of page 3.
  
  codEstaciones <- read.csv2('data/codeStations.csv')
  codURL <- as.numeric(substr(codEstaciones$Codigo, 7, 8))
  
  ## The information of each measuring station is available at its own webpage, defined by codURL
  URLs <- paste('http://www.mambiente.munimadrid.es/opencms/opencms/calaire/contenidos/estaciones/estacion', codURL, '.html', sep = '')
#+end_src

** \floweroneleft Data Arrangement
#+begin_src R :exports none
##################################################################
## Data arrangement
##################################################################
#+end_src
The station webpage includes several tables that can be extracted with
the =readHTMLTable= function of the =XML= package.  The longitude and
latitude are included in the second table. The =ub2dms= function
cleans this table and converts the strings to the =DMS= class defined
by the =sp= package to represent degrees, minutes, and decimal
seconds.


#+INDEX: Subjects!Web scraping
#+INDEX: Packages!XML@\texttt{XML}
#+INDEX: Packages!sp@\texttt{sp}
#+INDEX: Subjects!Data processing and cleaning

#+begin_src R
  library(XML)
  library(sp)
  
  ## Access each webpage, retrieve tables and extract long/lat data
  coords <- lapply(URLs, function(est){
    tables <- readHTMLTable(est)
    location <- tables[[2]]
    ## Clean the table content and convert to dms format
    ub2dms <- function(x){
      ch <- as.character(x)
      ch <- sub(',', '.', ch) 
      ch <- sub('O', 'W', ch) ## Some stations use "O" instead of "W"
      as.numeric(char2dms(ch, "º", "'", "'' "))
    }
    long <- ub2dms(location[2,1])
    lat <- ub2dms(location[2,2])
    alt <- as.numeric(sub(' m.', '', location[2, 3]))
  
    coords <- data.frame(long = long, lat = lat, alt = alt)
  
    coords
  })
  
  airStations <- cbind(codEstaciones, do.call(rbind, coords))
  
  ## The longitude of "El Pardo" station is wrong (positive instead of negative)
  airStations$long[22] <- -airStations$long[22]
  
  write.csv2(airStations, file = 'data/airStations.csv')
#+end_src

The 2011 air pollution data are available from the Madrid City Council
webpage[fn:2] and at the =data= folder of the book repository. The
structure of the file is documented in the INTPHORA-DIA
document[fn:3]. The =readLines= function reads the file and a =lapply=
loop processes each line. The result is stored in the file
=airQuality.csv=


#+INDEX: Subjects!String manipulation

#+begin_src R 
rawData <- readLines('data/Datos11.txt')
## This loop reads each line and extracts fields as defined by the
## INTPHORA file:
## http://www.mambiente.munimadrid.es/opencms/export/sites/default/calaire/Anexos/INTPHORA-DIA.pdf
datos11 <- lapply(rawData, function(x){
    codEst <- substr(x, 1, 8)
    codParam <- substr(x, 9, 10)
    codTec <- substr(x, 11, 12)
    codPeriod <- substr(x, 13, 14)
    month <- substr(x, 17, 18)
    dat <- substr(x, 19, nchar(x))
    ## "N" used for impossible days (31st April)
    idxN <- gregexpr('N', dat)[[1]]
    if (idxN==-1) idxN <- numeric(0)
    nZeroDays <- length(idxN)
    day <- seq(1, 31-nZeroDays)
    ## Substitute V and N with ";" to split data from different days
    dat <- gsub('[VN]+', ';', dat)
    dat <- as.numeric(strsplit(dat, ';')[[1]])
    ## Only data from valid days
    dat <- dat[day]
    res <- data.frame(codEst, codParam, ##codTec, codPeriod,
                      month, day, year = 2016,
                      dat)
})
datos11 <- do.call(rbind, datos11)

write.csv2(datos11, 'data/airQuality.csv')
#+end_src


** Combine Data and Spatial Locations
#+begin_src R :exports none
##################################################################
## Combine data and spatial locations
##################################################################
#+end_src
Our next step is to combine the data and spatial information. The
locations are contained in =airStations=, a =data.frame= that is
converted to an =SpatialPointsDataFrame= object with the =coordinates=
method.


#+INDEX: Data!Air quality in Madrid
#+INDEX: Packages!sp@\texttt{sp}

#+begin_src R 
  library(sp)
  
  ## Spatial location of stations
  airStations <- read.csv2('data/airStations.csv')
  coordinates(airStations) <- ~ long + lat
  ## Geographical projection
  proj4string(airStations) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")
#+end_src

#+RESULTS:

On the other hand, the =airQuality= =data.frame= comprises the air
quality daily measurements. We will retain only the $NO_2$ time
series.
#+begin_src R
  ## Measurements data
  airQuality <- read.csv2('data/airQuality.csv')
  ## Only interested in NO2 
  NO2 <- airQuality[airQuality$codParam==8, ]
#+end_src

#+RESULTS:

We will represent each station using aggregated values (mean, median,
and standard deviation) computed with =aggregate=:


#+begin_src R 
  NO2agg <- aggregate(dat ~ codEst, data = NO2,
                      FUN = function(x) {
                          c(mean = signif(mean(x), 3),
                            median = median(x),
                            sd = signif(sd(x), 3))
                          })
  NO2agg <- do.call(cbind, NO2agg)
  NO2agg <- as.data.frame(NO2agg)
#+end_src


The aggregated values (a =data.frame=) and the spatial information (a
=SpatialPointsDataFrame=) are combined with the =spCbind= method from
the =maptools= package to create a new
=SpatialPointsDataFrame=. Previously, the =data.frame= is reordered by
matching against the shared key column (=airStations$Codigo= and
=NO2agg$codEst=):


#+INDEX: Packages!rgdal@\texttt{rgdal}
#+INDEX: Packages!maptools@\texttt{maptools}

#+begin_src R
library(rgdal)
library(maptools)
## Link aggregated data with stations to obtain a SpatialPointsDataFrame.
## Codigo and codEst are the stations codes
idxNO2 <- match(airStations$Codigo, NO2agg$codEst)
NO2sp <- spCbind(airStations[, c('Nombre', 'alt')], NO2agg[idxNO2, ])
## Save the result
writeOGR(NO2sp, dsn = 'data/', layer = 'NO2sp',
         driver = 'ESRI Shapefile')
#+end_src



** Photographs of the stations
label:sec:photographs_stations

#+begin_src R :exports none
##################################################################
## Photographs of the stations
##################################################################
#+end_src

#+INDEX: Packages!XML@\texttt{XML}
\nomenclature{XML}{Extensible Markup Language, a markup language that defines a set of rules for encoding documents in a format that is both human-readable and machine-readable.}

The photographs of the stations are used for the tooltips of the
interactive graphics (Section ref:sec:interactive_bubble). These
photographs are downloaded from the Munimadrid webpage[fn:8] with the
functions of the =XML= package.

The =htmlParse= function from the =XML= package parses each station
page, and the station photograph is extracted with =getNodeSet= and
=xmlAttrs=.


#+begin_src R :eval no-export
library(XML)

old <- setwd('images')
for (i in 1:nrow(NO2df))
{
    codEst <- NO2df[i, "codEst"]
    ## Webpage of each station
    codURL <- as.numeric(substr(codEst, 7, 8))
    rootURL <- 'http://www.mambiente.munimadrid.es'
    stationURL <- paste(rootURL,
                        '/opencms/opencms/calaire/contenidos/estaciones/estacion',
                        codURL, '.html', sep = '')
    content <- htmlParse(stationURL, encoding = 'utf8')
    ## Extracted with http://www.selectorgadget.com/
    xPath <- '//*[contains(concat( " ", @class, " " ), concat( " ", "imagen_1", " " ))]'
    imageStation <- getNodeSet(content, xPath)[[1]]
    imageURL <- xmlAttrs(imageStation)[1]
    imageURL <- paste(rootURL, imageURL, sep = '')
    download.file(imageURL, destfile = paste(codEst, '.jpg', sep = ''))
}
setwd(old)
#+end_src

* Spanish General Elections
label:sec:dataChoropleth

#+begin_src R :exports none
##################################################################
## Spanish General Elections
##################################################################
#+end_src

The results from the 2016 Spanish general elections[fn:9] are
available from the Ministry webpage[fn:10] and at the =data= folder of
the book repository. Each region of the map will represent the
percentage of votes (=pcMax=) obtained by the predominant political
option (=whichMax=) at the corresponding municipality.  Only six
groups are considered: the four main parties (=PP=, =PSOE=, =UP=,
=Cs=), the abstention results (=ABS=), and the remaining parties
(=OTH=). Each region will be identified by the =PROVMUN= code.

#+INDEX: Data!INE
#+INDEX: Data!Spanish General Elections
#+INDEX: Subjects!Data processing and cleaning

#+begin_src R 
dat2016 <- read.csv('data/GeneralSpanishElections2016.csv')

census <- dat2016$Total.censo.electoral
validVotes <- dat2016$Votos.válidos
## Election results per political party and municipality
votesData <- dat2016[, -(1:13)]
## Abstention as an additional party
votesData$ABS <- census - validVotes
## UP is a coalition of several parties
UPcols <- grep("PODEMOS|ECP", names(votesData))
votesData$UP <- rowSums(votesData[, UPcols])
votesData[, UPcols] <- NULL
## Winner party at each municipality
whichMax <- apply(votesData,  1, function(x)names(votesData)[which.max(x)])
## Results of the winner party at each municipality
Max <- apply(votesData, 1, max)
## OTH for everything but PP, PSOE, UP, Cs, and ABS
whichMax[!(whichMax %in% c('PP', 'PSOE', 'UP', 'C.s', 'ABS'))] <- 'OTH'
## Percentage of votes with the electoral census
pcMax <- Max/census * 100

## Province-Municipality code. sprintf formats a number with leading zeros.
PROVMUN <- with(dat2016, paste(sprintf('%02d', Código.de.Provincia),
                               sprintf('%03d', Código.de.Municipio),
                               sep=""))

votes2016 <- data.frame(PROVMUN, whichMax, Max, pcMax)
write.csv(votes2016, 'data/votes2016.csv', row.names = FALSE)
#+end_src

#+begin_src R :results output :exports results :tangle no
votes2016 <- read.csv('data/votes2016.csv',
                        colClasses = c('factor', 'factor', 'numeric', 'numeric'))

summary(votes2016)
#+end_src

#+RESULTS:
:     PROVMUN     whichMax         Max             pcMax      
:  01001  :   1   ABS :2817   Min.   :     2   Min.   :21.33  
:  01002  :   1   C.s :   3   1st Qu.:    54   1st Qu.:31.69  
:  01003  :   1   OTH : 170   Median :   162   Median :35.64  
:  01004  :   1   PP  :4214   Mean   :  1394   Mean   :37.58  
:  01006  :   1   PSOE: 783   3rd Qu.:   637   3rd Qu.:41.25  
:  01008  :   1   UP  : 138   Max.   :696804   Max.   :94.74  
:  (Other):8119


** Administrative Boundaries

#+begin_src R :exports none
##################################################################
## Administrative boundaries
##################################################################
#+end_src

The Spanish administrative boundaries are available as shapefiles at
the INE (Instituto Nacional de Estadística) webpage[fn:7]. Both the
municipalities, =spMap=, and province boundaries, =provinces=, are
read as =SpatialPolygonsDataFrame= with =readOGR=.


#+INDEX: Packages!rgdal@\texttt{rgdal}
#+INDEX: Packages!sp@\texttt{sp}

#+begin_src R
library(sp)
library(rgdal)
#+end_src


#+INDEX: Data!INE

#+begin_src R :eval no-export
old <- setwd(tempdir())

download.file('ftp://www.ine.es/pcaxis/mapas_completo_municipal.rar',
              'mapas_completo_municipal.rar')
system2('unrar', c('e', 'mapas_completo_municipal.rar'))

spMap <- readOGR("esp_muni_0109.shp",
                 p4s = "+proj=utm +zone=30 +ellps=GRS80 +units=m +no_defs")
Encoding(levels(spMap$NOMBRE)) <- "latin1"

setwd(old)
#+end_src

#+begin_src R :exports none :tangle no
spMap <- readOGR("/home/datos/mapas_completo_municipal/esp_muni_0109.shp",
                 p4s = "+proj=utm +zone=30 +ellps=GRS80 +units=m +no_defs")
Encoding(levels(spMap$NOMBRE)) <- "latin1"
#+end_src  

Some of the polygons are repeated and can be dissolved with
=unionSpatialPolygons= (the =rgeos= package must be installed).

#+begin_src R 
## dissolve repeated polygons
spPols <- unionSpatialPolygons(spMap, spMap$PROVMUN) 
#+end_src

The main step is to link the data with the polygons. The =ID= slot of
each polygon is the key to find the correspondent registry in the
=votes2016= dataset.
#+begin_src R
votes2016 <- read.csv('data/votes2016.csv',
                        colClasses = c('factor', 'factor', 'numeric', 'numeric'))

## Match polygons and data using ID slot and PROVMUN column
IDs <- sapply(spPols@polygons, function(x)x@ID)
idx <- match(IDs, votes2016$PROVMUN)
  
##Places without information
idxNA <- which(is.na(idx))

##Information to be added to the SpatialPolygons object
dat2add <- votes2016[idx, ]

## SpatialPolygonsDataFrame uses row names to match polygons with data
row.names(dat2add) <- IDs
spMapVotes <- SpatialPolygonsDataFrame(spPols, dat2add)

## Drop those places without information
spMapVotes0 <- spMapVotes[-idxNA, ]

## Save the result
writeOGR(spMapVotes0, dsn = 'data/', layer = 'spMapVotes0',
         drive = 'ESRI Shapefile')
#+end_src

\nomenclature{shapefile}{A spatial data format. It stores geometry and attribute information for the spatial features in a data set.}

Finally, Spanish maps are commonly displayed with the Canarian islands next
to the peninsula. First we have to extract the polygons of the
islands and the polygons of the peninsula, and then shift the
coordinates of the islands with =elide=. Finally, a new
=SpatialPolygons= object binds the shifted islands with the
peninsula.

#+begin_src R
## Extract Canarias islands from the SpatialPolygons object
canarias <-  sapply(spMapVotes0@polygons, function(x)substr(x@ID, 1, 2) %in% c("35",  "38"))
peninsula <- spMapVotes0[!canarias,]
island <- spMapVotes0[canarias,]

## Shift the island extent box to position them at the bottom right corner
dy <- bbox(peninsula)[2,1] - bbox(island)[2,1]
dx <- bbox(peninsula)[1,2] - bbox(island)[1,2]
island2 <- elide(island, shift = c(dx, dy))
bbIslands <- bbox(island2)
proj4string(island2) <- proj4string(peninsula)

## Bind Peninsula (without islands) with shifted islands
spMapVotes <- rbind(peninsula, island2)

## Save the result
writeOGR(spMapVotes, dsn = 'data/', layer = 'spMapVotes',
         drive = 'ESRI Shapefile')
#+end_src

* CM SAF
\label{sec:CMSAF}

#+begin_src R :exports none
  ##################################################################
  ## CM SAF
  ##################################################################
#+end_src

The Satellite Application Facility on Climate Monitoring (CM SAF) is a
joint venture of the Royal Netherlands Meteorological Institute, the
Swedish Meteorological and Hydrological Institute, the Royal
Meteorological Institute of Belgium, the Finnish Meteorological
Institute, the Deutscher Wetterdienst, Meteoswiss, and the UK
MetOffice, along with collaboration of the European Organization for
the Exploitation of Meteorological Satellites (EUMETSAT)
\cite{CMSAF}. The CM-SAF was funded in 1992 to generate and store
monthly and daily averages of meteorological data measured in a
continuous way with a spatial resolution of $\ang{0.03}$ (15
kilometers). The CM SAF provides two categories of data: operational
products and climate data. The operational products are built on data
that are validated with on-ground stations and then is provided in
near-real-time to develop variability studies in diurnal and seasonal
time scales. However, climate data are long-term data series to assess
inter-annual variability \cite{Posselt.Mueller.ea2012}.

\nomenclature{CM-SAF}{Satellite Application Facility on Climate Monitoring}
\nomenclature{SIS}{Shortwave incoming solar radiation}

In this chapter we will display the annual average of the shortwave
incoming solar radiation product (SIS) incident over Spain during
2008, computed from the monthly means of this variable. SIS collates
shortwave radiation ($0.2$ to $\SI{4}{\micro\meter}$ wavelength range)
reaching a horizontal unit Earth surface obtained by processing
information from geostationary satellites (METEOSAT) and also from
polar satellites (MetOp and NOAA) \cite{Schulz.Albert.ea2009} and then
validated with high-quality on-ground measurements from the Baseline
Surface Radiation Network (BSRN)[fn:4].

The monthly means of SIS are available upon request from the CM SAF
webpage \cite{Posselt.Muller.ea2011} and at the =data= folder of the
book repository. Data from CM-SAF is published as raster files using
the NetCDF format. The =raster= package provides the =stack= function
to read a set of files and create a =RasterStack= object, where each
layer stores the content of a file. Therefore, the twelve raster files
of monthly averages produce a =RasterStack= with twelve layers.

\nomenclature{NetCDF}{Network Common Data Form, a set of software libraries and self-describing, machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.}
#+INDEX: Data!CM SAF
#+INDEX: Data!Solar radiation
#+INDEX: Subjects!Data processing and cleaning

#+INDEX: Packages!raster@\texttt{raster}

#+begin_src R
  library(raster)
  
  tmp <- tempdir()
  unzip('data/SISmm2008_CMSAF.zip', exdir = tmp)
  filesCMSAF <- dir(tmp, pattern = 'SISmm')
  SISmm <- stack(paste(tmp, filesCMSAF, sep = '/'))
  ## CM-SAF data is average daily irradiance (W/m2). Multiply by 24
  ## hours to obtain daily irradiation (Wh/m2)
  SISmm <- SISmm * 24
#+end_src

The =RasterLayer= object with annual averages is computed from the
monthly means and stored using the native format of the =raster=
package.
#+begin_src R 
  ## Monthly irradiation: each month by the corresponding number of days
  daysMonth <- c(31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)
  SISm <- SISmm * daysMonth / 1000 ## kWh/m2
  ## Annual average
  SISav <- sum(SISm)/sum(daysMonth)
  writeRaster(SISav, file = 'SISav')
#+end_src


* Land Cover and Population Rasters

The NASA's Earth Observing System (EOS)[fn:5] is a coordinated series
of polar-orbiting and low-inclination satellites for long-term global
observations of the land surface, biosphere, solid Earth, atmosphere,
and oceans. NEO-NASA[fn:6], one of projects included in EOS, provides
a repository of global data imagery. We use the population density and
land cover classification rasters. Both rasters must be downloaded
from their respective webpages as Geo-TIFF files.

\nomenclature{NEO-NASA}{NASA Earth Observations, part of the NASA’s Earth Observing System (EOS).}
\nomenclature{Geo-TIFF}{A public domain metadata standard which allows georeferencing information to be embedded within a TIFF file.}
\nomenclature{TIFF}{Tagged Image File Format, a computer file format for storing raster graphics images.}

#+INDEX: Data!Population density
#+INDEX: Data!Land cover

#+begin_src R
library(raster)
## http://neo.sci.gsfc.nasa.gov/Search.html?group=64
pop <- raster('875430rgb-167772161.0.FLOAT.TIFF')
## http://neo.sci.gsfc.nasa.gov/Search.html?group=20
landClass <- raster('241243rgb-167772161.0.TIFF')
#+end_src


* Footnotes

[fn:8] http://www.mambiente.munimadrid.es/opencms/opencms/calaire/SistemaIntegral/SistVigilancia/Estaciones/


[fn:7] http://www.ine.es/ > Products and services > Publications > Download the PC-Axis program > Municipal maps

[fn:1] http://www.eea.europa.eu/soer/countries/es/

[fn:2] http://www.mambiente.munimadrid.es/opencms/opencms/calaire/consulta/descarga_opendata.html

[fn:3] http://www.mambiente.munimadrid.es/opencms/export/sites/default/calaire/Anexos/INTPHORA-DIA.pdf

[fn:4] http://www.bsrn.awi.de/en/home/

[fn:5] http://eospso.gsfc.nasa.gov/

[fn:6] http://neo.sci.gsfc.nasa.gov

[fn:9] https://en.wikipedia.org/wiki/Spanish_general_election,_2016

[fn:10] http://www.infoelectoral.mir.es/infoelectoral/docxl/02_201606_1.zip



